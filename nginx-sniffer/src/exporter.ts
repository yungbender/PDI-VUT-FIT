/**
 * Nginx sniffer.
 * 
 * Authors: Tomas Sasak (xsasak01), Jakub Frejlach (xfrejl00)
 */
import { Kafka, Producer } from 'kafkajs';
import { promises as afs } from 'fs';
import *Â as fs from 'fs';

/**
 * Nginx njs request logs folder.
 */
const logsLocation = process.env.LOGS_FOLDER;

/**
 * Global kafka object.
 */
const kafka = new Kafka({
    clientId: `${process.env.KAFKA_CLIENT_ID}`,
    brokers: [`${process.env.KAFKA_BROKER}:${process.env.KAFKA_BROKER_PORT}`]
});

/**
 * Global kafka producer object.
 */
let producer: Producer;

/**
 * Creates kafka producer and connects to broker.
 */
const createProducer = async () => {
    while(true) {
        let producer = kafka.producer();
        try {
            await producer.connect();
            return producer;
        } catch(e) {
            console.log("Cannot connect to Kafka broker, retrying");
            await new Promise(r => setTimeout(r, 2000));
        }
    }
};

/**
 * Loops until it gets connected to kafka.
 */
const waitOnProducer = async () => {
    while(true) {
        if(producer !== undefined)
            break;
        await new Promise(res => setTimeout(res, 1000));
    }
};

/**
 * Uploads missed log files in log folder to kafka.
 */
const uploadMissing = async() => {
    let files = await afs.readdir(logsLocation!);
    console.log(`Processing missing files: ${files.length}`);
    for(let file of files) {
        await fileCallback("change", file);
    }
};

/**
 * Callback when file changes in folder.
 * Uploads each file log to kafka and deletes it afterwards.
 */
const fileCallback = async (eventType: string, filename: string) => {
    await waitOnProducer();

    if(eventType !== "change")
        return;

    console.log(`Processing log ${filename}`);

    let filePath = `${logsLocation}/${filename}`;
    let file = await afs.readFile(filePath);

    console.log(`Sending ${filename} content to kafka`);

    await producer.send({
        topic: process.env.KAFKA_INGRESS_TOPIC!,
        messages: [
            {value: file}
        ],
    });

    console.log(`Deleting ${filename} log`);
    await afs.unlink(filePath);
};

/**
 * Sniffer watches set logs folder, where nginx exports
 * through NJS logs with our needed attributes for each requests.
 * Each log is sent to the kafka to be processed by spark.
 */
const main = () => {
    console.log(`Starting nginx logs exporter.`);
    createProducer().then((res) => producer = res);

    // setup listener for logs folder with logs generated by nginx njs
    if(logsLocation === undefined) {
        console.error("Logs location path not defined, aborting");
        return;
    }
    // upload logs which got missed and are in logs folder
    uploadMissing().then();
    // start watching folder
    fs.watch(logsLocation, {
        persistent: true,
        recursive: false,
        encoding: "utf-8",
    }, fileCallback);
};

main();

export default { main };
